
<h3>Experience of working with and managing large data sets </h3>
My work on developing and evaluating vegetation models has involved processing a range of climate/GIS data products, such as raw and processed satellite data (see e.g. <cite>Kelley2008; Prentice2011; Kelley2013; Kelley2014a; Kelley2014b</cite>); vector ground observation (<cite>Kelley2013; Kelley2014a; kelley2014modelling; Harrison</cite>); historical climate and climate reanalysis data <citep>Prentice2011; Kelley2014a; kelley2014modelling</citep>; and climate model data for past <citep>Ciais2011</citep> and future climates <citep>Kelley2014b; Harrisonc</citep>. Recent work on simulating future land-surface processes  provided the best example of managing large and complex datasets. Here, I initially drove the LPX-DGVM  with detrended historic climate data, pre-industrial land use and atmospheric compositions in order to spin-up the model. I then used historic climate, land use and atmospheric composition to drive the model up to the modern day. This then transitioned into 36 different climate realisations, based on 9 CMIP5 models from two different RCPs, and four atmospheric CO2 pathways. Each step involved processing and organising several GBs worth of data, and historic simulations involved model evaluation against remote sensed and ground-based observations in order to justify model use. This one project was all initially published in <citet>Kelley2014b</citet>, but has since spawned other papers (e.g. <cite>Harrisonc; Ukkola</cite>).



<h2> References </h2>
<References> MetOfficeClimMod/refList.bib </References>
